{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values in Data\n",
    "\n",
    "* missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. \n",
    "\n",
    "&nbsp;\n",
    "* **```Missing data present various problems```**\n",
    "\n",
    "     * First, the absence of data reduces statistical power, which refers to the probability that the test will reject the null hypothesis when it is false. \n",
    "     * Second, the lost data can cause bias in the estimation of parameters. \n",
    "     * Third, it can reduce the representativeness of the samples.\n",
    "     \n",
    "     &nbsp;\n",
    "     \n",
    "* **```Common ways to Handle Missing Data```**\n",
    "\n",
    "     * ```Encoding``` the Null Values with ```-1 or -9999```.\n",
    "     * ```Casewise deletion``` of Missing Data, i.e., In certain cases, where more than 60% of the data is missing It is better to completely remove that column.\n",
    "     * Replacing Missing Values with Mean, Median, and Mode value of the feature in which they occur\n",
    "         * Use ```Mean``` Values to impute Missing values when the data is continuous variable and when there are lesser or no outliers present in the data.\n",
    "         * Use ```Median``` Values to impute Missing Values when the data is continuous variable and when there are huge number of outliers present in the data.\n",
    "         * Use ```Mode Values``` to impute Missing Values when the daata is categorical variable.\n",
    "      * Using the ```Predictive Models```, to impute the missing values.\n",
    "      * Use the Missing Values to Create a New Feature, ```Feature Engineering```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1470, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets import a dataset to perform the operations\n",
    "data = pd.read_csv('Datasets/employee.csv')\n",
    "\n",
    "# lets check the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the structure of the dataset\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Functions which will help us to identify the null values present in the dataframes\n",
    "\n",
    "#### The Functions which help us to know whether the data is null or not\n",
    "* ```isnull()```: Indicates the presence of Missing values in a dataset, return boolean values. i.e., It will return True if the data is missing and False if the data is not missing.\n",
    "* ```notnull()```: This Function is completely the Opposite of ```isnull()```, It also returns boolean values.\n",
    "\n",
    "#### The Functions which helps us to compute operations to check  whether all or some data is missing\n",
    "* ```any()```: It will be used where we want to include all the data for operations and Identification.\n",
    "* ```all()```: It will be used where we are only checking on some or any of the data for operations or Identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets first check if there is any null value present in the data\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that, there are no missing values in the dataset**\n",
    "\n",
    "* Using ```isnull()``` function returns true, If there any data present in the cell and false if there is no data present in the cell.\n",
    "&nbsp;\n",
    "\n",
    "* Using ```isnull().sum()``` function would return the sum of null values present in each of the columns.\n",
    "&nbsp;\n",
    "\n",
    "* Using ```isnull().sum().sum()``` function would return the totak number of null values or missing values present in a dataset or dataframe.\n",
    "&nbsp;\n",
    "\n",
    "* In the Above Result we can see that every columns present in the dataset are having 0 null values, that means there is no null data in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>03-09-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>03-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb          Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford    68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford     85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford  25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "\n",
       "         Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  03-09-2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  03-12-2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  04-02-2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try to take another dataframe, and try to handle missing values in the dataframe\n",
    "\n",
    "data = pd.read_csv('Datasets/melbourne.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23547 entries, 0 to 23546\n",
      "Data columns (total 21 columns):\n",
      "Suburb           23547 non-null object\n",
      "Address          23547 non-null object\n",
      "Rooms            23547 non-null int64\n",
      "Type             23547 non-null object\n",
      "Price            18396 non-null float64\n",
      "Method           23547 non-null object\n",
      "SellerG          23547 non-null object\n",
      "Date             23547 non-null object\n",
      "Distance         23546 non-null float64\n",
      "Postcode         23546 non-null float64\n",
      "Bedroom2         19066 non-null float64\n",
      "Bathroom         19063 non-null float64\n",
      "Car              18921 non-null float64\n",
      "Landsize         17410 non-null float64\n",
      "BuildingArea     10018 non-null float64\n",
      "YearBuilt        11540 non-null float64\n",
      "CouncilArea      15656 non-null object\n",
      "Lattitude        19243 non-null float64\n",
      "Longtitude       19243 non-null float64\n",
      "Regionname       23546 non-null object\n",
      "Propertycount    23546 non-null float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# lets check the basic information about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check whether this dataset is having any null values or not\n",
    "\n",
    "# first lets check how many rows are having all the null values\n",
    "data.isnull().all(axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The returned value is the total number of missing values in the dataframe\n",
    "* 66, 918 number of data points are missing that is huge.\n",
    "* let's also check the details of the missing values.\n",
    "* In the detailed report we will be able to check how many missing values are associated with each of teh columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb               0\n",
       "Address              0\n",
       "Rooms                0\n",
       "Type                 0\n",
       "Price             5151\n",
       "Method               0\n",
       "SellerG              0\n",
       "Date                 0\n",
       "Distance             1\n",
       "Postcode             1\n",
       "Bedroom2          4481\n",
       "Bathroom          4484\n",
       "Car               4626\n",
       "Landsize          6137\n",
       "BuildingArea     13529\n",
       "YearBuilt        12007\n",
       "CouncilArea       7891\n",
       "Lattitude         4304\n",
       "Longtitude        4304\n",
       "Regionname           1\n",
       "Propertycount        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the number of missing values in the dataset\n",
    "# we are check the missing values in the context of columns\n",
    "data.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that there are many columns which are having null values, Infact there are some columns where we have huge number of missing values.\n",
    "* lets also check the percentage of missing values present in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Handle Missing Values from a Dataframe\n",
    "\n",
    "* **We have already discussed the ways to handle the missing values from the Dataset, but when talking about it in broad sense then only two major choices:**\n",
    "    * To ```drop/delete``` the missing values\n",
    "    * To ```impute``` the missinng values\n",
    "    \n",
    "* **We have to take decision regarding which of the two options to go with depending on the missing values**.\n",
    "    * We can drop/delete the missinng values only when the missing percentage is more than 50% or it is not so important.\n",
    "    * in that case, we have to impute the values using any of the methods listed in the introduction part.\n",
    "    \n",
    "lets take some examples using the available dataset to check how to impute or delelete the missing values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods we will use to Impute Missing Values\n",
    "\n",
    "* There are many ways to Impute Missing Values, some of them which are popularly used:\n",
    "    * ```dropna()```: This Function is used to drops the missing values from a dataset and returns the rest of the dataframe.\n",
    "    * ```fillna()```: This Function is used to replace the missing value with a specified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suburb            0.00\n",
      "Address           0.00\n",
      "Rooms             0.00\n",
      "Type              0.00\n",
      "Price            21.88\n",
      "Method            0.00\n",
      "SellerG           0.00\n",
      "Date              0.00\n",
      "Distance          0.00\n",
      "Postcode          0.00\n",
      "Bedroom2         19.03\n",
      "Bathroom         19.04\n",
      "Car              19.65\n",
      "Landsize         26.06\n",
      "BuildingArea     57.46\n",
      "YearBuilt        50.99\n",
      "CouncilArea      33.51\n",
      "Lattitude        18.28\n",
      "Longtitude       18.28\n",
      "Regionname        0.00\n",
      "Propertycount     0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lets check the percentage of missing values in the columns of the dataset\n",
    "\n",
    "percentage_of_missing_values = round(100*(data.isnull().sum()/len(data.index)), 2)\n",
    "print(percentage_of_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: green;\">It can be noticed very easily from the above results that there are many columns have huge percentage of data missing from the dataset. There are columns which are having ```18% to 26%``` of values missing from the data, and also there are some columns which are having ```33% to 56%``` of values missing from the data.\n",
    "\n",
    "* What action should we take, should we remove them all, or impute.\n",
    "    * We ```cannot remove the columns having 18% to 26% missing values```, so In this case we will have to impute the missing values using one of the methods.\n",
    "        * It is very important to impute the missing values for these columns as If we remove these columns from the data having only 18 to 26% of the missing values then we will face huge data loss, In that case, We might lose some of the very important and relevant data for the analysis and results.\n",
    "    \n",
    "    * But, ```We can remove the columns having 33 to 56% of missing values```, so In this case will have to drop these columns from the data.\n",
    "        * It is very important to remove these columns because if we impute these missing values then we can introduce a huge bias into the data, which will be bad for the analysis of the data, It might also return inappropriate and misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the Columns using drop() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function drop in module pandas.core.frame:\n",
      "\n",
      "drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      "    Drop specified labels from rows or columns.\n",
      "    \n",
      "    Remove rows or columns by specifying label names and corresponding\n",
      "    axis, or by specifying directly index or column names. When using a\n",
      "    multi-index, labels on different levels can be removed by specifying\n",
      "    the level.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    labels : single label or list-like\n",
      "        Index or column labels to drop.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Whether to drop labels from the index (0 or 'index') or\n",
      "        columns (1 or 'columns').\n",
      "    index : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=0``\n",
      "        is equivalent to ``index=labels``).\n",
      "    \n",
      "        .. versionadded:: 0.21.0\n",
      "    columns : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=1``\n",
      "        is equivalent to ``columns=labels``).\n",
      "    \n",
      "        .. versionadded:: 0.21.0\n",
      "    level : int or level name, optional\n",
      "        For MultiIndex, level from which the labels will be removed.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    errors : {'ignore', 'raise'}, default 'raise'\n",
      "        If 'ignore', suppress error and only existing labels are\n",
      "        dropped.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame without the removed index or column labels.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If any of the labels is not found in the selected axis.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.loc : Label-location based indexer for selection by label.\n",
      "    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      "        where (all or any) data are missing.\n",
      "    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      "        removed, optionally only considering certain columns.\n",
      "    Series.drop : Return Series with specified index labels removed.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\n",
      "    ...                   columns=['A', 'B', 'C', 'D'])\n",
      "    >>> df\n",
      "       A  B   C   D\n",
      "    0  0  1   2   3\n",
      "    1  4  5   6   7\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns\n",
      "    \n",
      "    >>> df.drop(['B', 'C'], axis=1)\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    >>> df.drop(columns=['B', 'C'])\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    Drop a row by index\n",
      "    \n",
      "    >>> df.drop([0, 1])\n",
      "       A  B   C   D\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns and/or rows of MultiIndex DataFrame\n",
      "    \n",
      "    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      "    ...                              ['speed', 'weight', 'length']],\n",
      "    ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "    ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      "    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      "    ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      "    ...                         [1, 0.8], [0.3, 0.2]])\n",
      "    >>> df\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "            length  1.5     1.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "            length  1.5     0.8\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "            length  0.3     0.2\n",
      "    \n",
      "    >>> df.drop(index='cow', columns='small')\n",
      "                    big\n",
      "    lama    speed   45.0\n",
      "            weight  200.0\n",
      "            length  1.5\n",
      "    falcon  speed   320.0\n",
      "            weight  1.0\n",
      "            length  0.3\n",
      "    \n",
      "    >>> df.drop(index='length', level=1)\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets check the documentation of drop function\n",
    "help(pd.DataFrame.drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'Lattitude', 'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the three columns having 33% to 56% of missing values in the dataset\n",
    "data = data.drop('BuildingArea', axis=1)\n",
    "data = data.drop('YearBuilt', axis=1)\n",
    "data = data.drop('CouncilArea', axis=1)\n",
    "\n",
    "# lets check the columns left after the deletion of above listed columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4278"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of rows having > 5 missing values\n",
    "# use len(df.index)\n",
    "len(data[data.isnull().sum(axis=1) > 5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining the rows having <= 5 NaNs\n",
    "data = data[data.isnull().sum(axis=1) <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            0.00\n",
       "Address           0.00\n",
       "Rooms             0.00\n",
       "Type              0.00\n",
       "Price            21.71\n",
       "Method            0.00\n",
       "SellerG           0.00\n",
       "Date              0.00\n",
       "Distance          0.00\n",
       "Postcode          0.00\n",
       "Bedroom2          1.05\n",
       "Bathroom          1.07\n",
       "Car               1.81\n",
       "Landsize          9.65\n",
       "Lattitude         0.13\n",
       "Longtitude        0.13\n",
       "Regionname        0.00\n",
       "Propertycount     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It can be seen that ```Price Column``` still has large number of missing values i.e., 21% of the data is missing. If we impute these values it will introduce heavy bias into the data and the results will be misleading so It is better to discard the rows where Price is having missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the rows where there is a missing value in the Price Column\n",
    "data = data[~np.isnan(data['Price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         1.05\n",
       "Bathroom         1.07\n",
       "Car              1.76\n",
       "Landsize         9.83\n",
       "Lattitude        0.15\n",
       "Longtitude       0.15\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we have Landsize, which is having high percentage of missing values, lets check the range of values present in the Landsize attribute of the data, so that we can impute the missing values present in the Landsize Attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     13603.000000\n",
       "mean        558.116371\n",
       "std        3987.326586\n",
       "min           0.000000\n",
       "25%         176.500000\n",
       "50%         440.000000\n",
       "75%         651.000000\n",
       "max      433014.000000\n",
       "Name: Landsize, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the description of values in the Landsize Column\n",
    "data['Landsize'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above description of the range of values present in the landsize columns supported by mean, standard deviatio, minimum, maximum, 25% percentile, 50% percentile, 75% percentile etc.\n",
    "\n",
    "* We can see that the Minimum value is 0 and Maximum value is 433014, there is huge difference so both mean and median function would not work\n",
    "\n",
    "* Also, there is a huge difference in the 25th, 50th, and 75th percentiles indicating that if we impute the values for Landsize column we will most probably introduce bias into the data.\n",
    "\n",
    "* It is most appropriate to remove the rows where we find null values for Landsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         0.00\n",
       "Bathroom         0.01\n",
       "Car              0.46\n",
       "Landsize         0.00\n",
       "Lattitude        0.16\n",
       "Longtitude       0.16\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing  all the rows where there is a null value in the landsize column\n",
    "data = data[~np.isnan(data['Landsize'])]\n",
    "\n",
    "# lets check the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that now we have very low fraction of missing values in the columns Bathroom, Car, Lattitude, and Longitude\n",
    "* Lets check the range values of Lattitude and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13581.000000</td>\n",
       "      <td>13581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-37.809204</td>\n",
       "      <td>144.995221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.103913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-37.856820</td>\n",
       "      <td>144.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-37.802360</td>\n",
       "      <td>145.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lattitude    Longtitude\n",
       "count  13581.000000  13581.000000\n",
       "mean     -37.809204    144.995221\n",
       "std        0.079257      0.103913\n",
       "min      -38.182550    144.431810\n",
       "25%      -37.856820    144.929600\n",
       "50%      -37.802360    145.000100\n",
       "75%      -37.756400    145.058320\n",
       "max      -37.408530    145.526350"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the values for lattitude and longitude\n",
    "data[['Lattitude','Longtitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing using fillna() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fillna in module pandas.core.frame:\n",
      "\n",
      "fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
      "    Fill NA/NaN values using the specified method.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    value : scalar, dict, Series, or DataFrame\n",
      "        Value to use to fill holes (e.g. 0), alternately a\n",
      "        dict/Series/DataFrame of values specifying which value to use for\n",
      "        each index (for a Series) or column (for a DataFrame).  Values not\n",
      "        in the dict/Series/DataFrame will not be filled. This value cannot\n",
      "        be a list.\n",
      "    method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      "        Method to use for filling holes in reindexed Series\n",
      "        pad / ffill: propagate last valid observation forward to next valid\n",
      "        backfill / bfill: use next valid observation to fill gap.\n",
      "    axis : {0 or 'index', 1 or 'columns'}\n",
      "        Axis along which to fill missing values.\n",
      "    inplace : bool, default False\n",
      "        If True, fill in-place. Note: this will modify any\n",
      "        other views on this object (e.g., a no-copy slice for a column in a\n",
      "        DataFrame).\n",
      "    limit : int, default None\n",
      "        If method is specified, this is the maximum number of consecutive\n",
      "        NaN values to forward/backward fill. In other words, if there is\n",
      "        a gap with more than this number of consecutive NaNs, it will only\n",
      "        be partially filled. If method is not specified, this is the\n",
      "        maximum number of entries along the entire axis where NaNs will be\n",
      "        filled. Must be greater than 0 if not None.\n",
      "    downcast : dict, default is None\n",
      "        A dict of item->dtype of what to downcast if possible,\n",
      "        or the string 'infer' which will try to downcast to an appropriate\n",
      "        equal type (e.g. float64 to int64 if possible).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Object with missing values filled.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    interpolate : Fill NaN values using interpolation.\n",
      "    reindex : Conform object to new index.\n",
      "    asfreq : Convert TimeSeries to specified frequency.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      "    ...                    [3, 4, np.nan, 1],\n",
      "    ...                    [np.nan, np.nan, np.nan, 5],\n",
      "    ...                    [np.nan, 3, np.nan, 4]],\n",
      "    ...                   columns=list('ABCD'))\n",
      "    >>> df\n",
      "         A    B   C  D\n",
      "    0  NaN  2.0 NaN  0\n",
      "    1  3.0  4.0 NaN  1\n",
      "    2  NaN  NaN NaN  5\n",
      "    3  NaN  3.0 NaN  4\n",
      "    \n",
      "    Replace all NaN elements with 0s.\n",
      "    \n",
      "    >>> df.fillna(0)\n",
      "        A   B   C   D\n",
      "    0   0.0 2.0 0.0 0\n",
      "    1   3.0 4.0 0.0 1\n",
      "    2   0.0 0.0 0.0 5\n",
      "    3   0.0 3.0 0.0 4\n",
      "    \n",
      "    We can also propagate non-null values forward or backward.\n",
      "    \n",
      "    >>> df.fillna(method='ffill')\n",
      "        A   B   C   D\n",
      "    0   NaN 2.0 NaN 0\n",
      "    1   3.0 4.0 NaN 1\n",
      "    2   3.0 4.0 NaN 5\n",
      "    3   3.0 3.0 NaN 4\n",
      "    \n",
      "    Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      "    2, and 3 respectively.\n",
      "    \n",
      "    >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "    >>> df.fillna(value=values)\n",
      "        A   B   C   D\n",
      "    0   0.0 2.0 2.0 0\n",
      "    1   3.0 4.0 2.0 1\n",
      "    2   0.0 1.0 2.0 5\n",
      "    3   0.0 3.0 2.0 4\n",
      "    \n",
      "    Only replace the first NaN element.\n",
      "    \n",
      "    >>> df.fillna(value=values, limit=1)\n",
      "        A   B   C   D\n",
      "    0   0.0 2.0 2.0 0\n",
      "    1   3.0 4.0 NaN 1\n",
      "    2   NaN 1.0 NaN 5\n",
      "    3   NaN 3.0 NaN 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as there is minute difference between the values of min, mean, max, 25th, 50th, and 75th percentile. \n",
    "# so we can use mean function to impute the values in lattitude and longtitude.\n",
    "\n",
    "data['Lattitude'].fillna(data['Lattitude'].mean(), inplace = True)\n",
    "data['Longtitude'].fillna(data['Longtitude'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7517\n",
       "2.0    4987\n",
       "3.0     921\n",
       "4.0     106\n",
       "0.0      34\n",
       "5.0      28\n",
       "6.0       5\n",
       "8.0       2\n",
       "7.0       2\n",
       "Name: Bathroom, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the values present in the Bathroom Column\n",
    "\n",
    "data['Bathroom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     5606\n",
       "1.0     5515\n",
       "0.0     1026\n",
       "3.0      748\n",
       "4.0      507\n",
       "5.0       63\n",
       "6.0       54\n",
       "8.0        9\n",
       "7.0        8\n",
       "10.0       3\n",
       "9.0        1\n",
       "Name: Car, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets also check the values present in the Car Column\n",
    "\n",
    "data['Car'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to impute the values in Categorical Columns using the Mode function\n",
    "\n",
    "data['Bathroom'].fillna(data['Bathroom'].mode()[0], inplace = True)\n",
    "data['Car'].fillna(data['Car'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the missing values present in the data\n",
    "\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that there no null values left in the dataset i.e., we are done with this tutorial on Handling Missing Values present in Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
